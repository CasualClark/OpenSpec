# Server-Sent Events (SSE) Configuration
# Optimized for real-time streaming with proper buffering and timeouts

# SSE-specific location block
location /sse {
    # Rate limiting for SSE endpoints
    limit_req zone=sse_burst burst=5 nodelay;
    
    # Connection limiting for SSE
    limit_conn conn_limit_per_ip 10;
    
    # SSE optimization - disable buffering completely
    proxy_buffering off;
    proxy_cache off;
    proxy_store off;
    
    # SSE headers
    proxy_set_header Connection "";
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Request-ID $request_id;
    
    # Disable acceleration buffering for SSE
    proxy_set_header X-Accel-Buffering no;
    
    # Extended timeouts for long-lived SSE connections
    proxy_connect_timeout 30s;
    proxy_send_timeout 3600s;  # 1 hour for SSE streams
    proxy_read_timeout 3600s;  # 1 hour for SSE streams
    
    # Keep-alive settings
    proxy_set_header Proxy-Connection "keep-alive";
    proxy_set_header Keep-Alive "timeout=300, max=1000";
    
    # Chunked transfer encoding for streaming
    proxy_set_header Transfer-Encoding "chunked";
    
    # Content-type handling
    proxy_set_header Accept "text/event-stream, application/json, */*";
    
    # SSE-specific proxy settings
    proxy_ignore_client_abort on;
    proxy_ignore_headers Cache-Control Expires Set-Cookie;
    
    # Pass to SSE-specific upstream
    proxy_pass http://task_mcp_sse_backend;
    
    # Error handling for SSE
    proxy_intercept_errors on;
    error_page 502 503 504 = /sse-error;
}

# SSE error handling location
location = /sse-error {
    internal;
    add_header Content-Type "text/event-stream";
    add_header Cache-Control "no-cache";
    add_header Connection "keep-alive";
    
    return 200 "event: error\ndata: {\"code\":\"STREAM_ERROR\",\"message\":\"Connection to backend failed\",\"retry\":5000}\n\n";
}

# NDJSON streaming endpoint configuration
location /mcp {
    # Rate limiting for MCP endpoints
    limit_req zone=api_burst burst=10 nodelay;
    
    # Connection limiting
    limit_conn conn_limit_per_ip 15;
    
    # Streaming optimization - minimal buffering for NDJSON
    proxy_buffering off;
    proxy_cache off;
    proxy_store off;
    
    # Streaming headers
    proxy_set_header Connection "";
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Request-ID $request_id;
    
    # Disable acceleration buffering for streaming
    proxy_set_header X-Accel-Buffering no;
    
    # Timeouts for streaming (shorter than SSE)
    proxy_connect_timeout 30s;
    proxy_send_timeout 300s;
    proxy_read_timeout 300s;
    
    # Content-type for NDJSON
    proxy_set_header Content-Type "application/x-ndjson";
    proxy_set_header Accept "application/x-ndjson, application/json, */*";
    
    # Pass to main backend
    proxy_pass http://task_mcp_backend;
    
    # Error handling
    proxy_intercept_errors on;
    error_page 502 503 504 = /mcp-error;
}

# MCP error handling
location = /mcp-error {
    internal;
    add_header Content-Type "application/x-ndjson";
    return 200 "{\"error\":{\"code\":\"STREAM_ERROR\",\"message\":\"Connection to backend failed\"}}\n";
}

# WebSocket support for future enhancements (if needed)
location /ws {
    proxy_pass http://task_mcp_backend;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # WebSocket timeouts
    proxy_connect_timeout 7d;
    proxy_send_timeout 7d;
    proxy_read_timeout 7d;
    
    # WebSocket-specific settings
    proxy_buffering off;
    proxy_cache off;
    proxy_read_timeout 86400s;
    proxy_send_timeout 86400s;
}